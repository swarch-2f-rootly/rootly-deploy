# Rootly Platform - Unified Docker Compose
services:
  queue-data-ingestion:
    image: confluentinc/cp-kafka:7.4.0
    container_name: queue-data-ingestion
    environment:
      - KAFKA_BROKER_ID=${KAFKA_BROKER_ID:-1}
      - KAFKA_ZOOKEEPER_CONNECT=${KAFKA_ZOOKEEPER_CONNECT:-zookeeper-data-ingestion:2181}
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:-PLAINTEXT:PLAINTEXT}
      - KAFKA_ADVERTISED_LISTENERS=${KAFKA_ADVERTISED_LISTENERS:-PLAINTEXT://queue-data-ingestion:9092}
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-1}
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR:-1}
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR:-1}
    depends_on:
      - zookeeper-data-ingestion
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "queue-data-ingestion:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  queue-ui-data-ingestion:
    image: provectuslabs/kafka-ui:latest
    container_name: queue-ui-data-ingestion
    environment:
      - KAFKA_CLUSTERS_0_NAME=${QUEUE_UI_CLUSTER_NAME:-local}
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=${QUEUE_UI_BOOTSTRAP_SERVERS:-queue-data-ingestion:9092}
    depends_on:
      - queue-data-ingestion
    networks:
      - rootly-private-network
    restart: unless-stopped

  zookeeper-data-ingestion:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper-data-ingestion
    environment:
      - ZOOKEEPER_CLIENT_PORT=${ZOOKEEPER_CLIENT_PORT:-2181}
      - ZOOKEEPER_TICK_TIME=${ZOOKEEPER_TICK_TIME:-2000}
    networks:
      - rootly-private-network
    restart: unless-stopped

  # InfluxDB - Time Series Database (Shared by both backends)
  db-data-processing:
    image: influxdb:2.7.5
    container_name: db-data-processing
    restart: unless-stopped
    volumes:
      - influxdb_data:/var/lib/influxdb2
      - ./influxdb/init:/docker-entrypoint-initdb.d
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=${DOCKER_INFLUXDB_INIT_MODE:-setup}
      - DOCKER_INFLUXDB_INIT_USERNAME=${DOCKER_INFLUXDB_INIT_USERNAME:-admin}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${DOCKER_INFLUXDB_INIT_PASSWORD:-admin123}
      - DOCKER_INFLUXDB_INIT_ORG=${DOCKER_INFLUXDB_INIT_ORG:-rootly}
      - DOCKER_INFLUXDB_INIT_BUCKET=${DOCKER_INFLUXDB_INIT_BUCKET:-agricultural_data}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${DOCKER_INFLUXDB_INIT_ADMIN_TOKEN:-super-secret-influx-token}
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # MinIO - Object Storage (Used by Data Processing Backend)
  stg-data-processing:
    image: minio/minio:latest
    container_name: stg-data-processing
    restart: unless-stopped
    volumes:
      - minio_data:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-admin123}
    command: server /data --console-address ":${MINIO_CONSOLE_PORT:-9001}"
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # PostgreSQL - Relational Database (Used by Authentication Backend)
  db-authentication-and-roles:
    image: postgres:15-alpine
    container_name: db-authentication-and-roles
    restart: unless-stopped
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-authentication_and_roles_db}
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-admin123}
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-authentication_and_roles_db}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # PostgreSQL - Relational Database (Used by User Plant Management Backend)
  db-user-plant-management:
    image: postgres:15-alpine
    container_name: db-user-plant-management
    restart: unless-stopped
    volumes:
      - postgres_user_plant_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${POSTGRES_USER_PLANT_DB:-user_plant_management_db}
      - POSTGRES_USER=${POSTGRES_USER_PLANT_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_USER_PLANT_PASSWORD:-admin123}
    networks:
      - rootly-private-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${POSTGRES_USER_PLANT_USER:-admin} -d ${POSTGRES_USER_PLANT_DB:-user_plant_management_db}",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # MinIO Auth - Object Storage for Profile Photos (Used by Authentication Backend)
  stg-authentication-and-roles:
    image: minio/minio:latest
    container_name: stg-authentication-and-roles
    restart: unless-stopped
    ports:
      - "${MINIO_AUTH_PORT:-9002}:9000"
      - "${MINIO_AUTH_CONSOLE_PORT:-9003}:9001"
    volumes:
      - minio_auth_data:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_AUTH_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_AUTH_ROOT_PASSWORD:-admin123}
    command: server /data --console-address ":9001"
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # MinIO User Plant - Object Storage for User Plant Management Backend
  stg-user-plant-management:
    image: minio/minio:latest
    container_name: stg-user-plant-management
    restart: unless-stopped
    volumes:
      - minio_user_plant_data:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_USER_PLANT_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_USER_PLANT_ROOT_PASSWORD:-admin123}
    command: server /data --console-address ":9001"
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Redis - Cache for Analytics Backend
  cache-analytics:
    image: redis:7.2-alpine
    container_name: cache-analytics
    restart: unless-stopped
    volumes:
      - redis_analytics_data:/data
    environment:
      - REDIS_PASSWORD=${REDIS_ANALYTICS_PASSWORD:-redis123}
    command: redis-server --requirepass ${REDIS_ANALYTICS_PASSWORD:-redis123} --appendonly yes --maxmemory ${REDIS_ANALYTICS_MAXMEMORY:-512mb} --maxmemory-policy allkeys-lru
    networks:
      - rootly-private-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s

  # ============================================================================
  # APPLICATION SERVICES
  # ============================================================================

  # Load Balancer para be-data-ingestion (componente separado, expuesto en red pública)
  # Genera configuración dinámicamente basado en DATA_INGESTION_REPLICAS
  load-balancer-ingestion:
    build:
      context: ../rootly-load-balancer-ingestion
      dockerfile: Dockerfile
    container_name: load-balancer
    ports:
      - "${LOAD_BALANCER_EXTERNAL_PORT:-8000}:80"
    environment:
      - DATA_INGESTION_REPLICAS=${DATA_INGESTION_REPLICAS:-1}
    env_file:
      - .env
    depends_on:
      - be-data-ingestion
    networks:
      - rootly-public-network
      - rootly-private-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1/lb-health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  be-data-ingestion:
    build:
      context: ../rootly-data-ingestion
      dockerfile: Dockerfile
    env_file:
      - .env
    depends_on:
      - queue-data-ingestion
    expose:
      - "8000"
    networks:
      - rootly-private-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: ${DATA_INGESTION_REPLICAS:-1}
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
  # Data Ingestion Backend (Go) - Handles data ingestion and storage
  be-data-processing:
    build:
      context: ../rootly-data-processing
      dockerfile: Dockerfile
    container_name: be-data-processing
    env_file:
      - .env
    depends_on:
      queue-data-ingestion:
        condition: service_started
      db-data-processing:
        condition: service_healthy
      stg-data-processing:
        condition: service_healthy
    environment:
      - HOST_IP=${HOST_IP:-}
      - EXTERNAL_PORT=${DATA_MANAGEMENT_EXTERNAL_PORT:-8002}
      - INFLUXDB_URL=http://db-data-processing:8086
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - rootly-private-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  # Load Balancer para be-analytics (componente interno)
  # Genera configuración dinámicamente basado en ANALYTICS_REPLICAS
  load-balancer-analytics:
    build:
      context: ../rootly-load-balancer-analytics
      dockerfile: Dockerfile
    container_name: load-balancer-analytics
    environment:
      - ANALYTICS_REPLICAS=${ANALYTICS_REPLICAS:-1}
    env_file:
      - .env
    depends_on:
      - be-analytics
    networks:
      - rootly-private-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1/lb-health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Analytics Backend (Python) - Provides analytics and insights
  be-analytics:
    build:
      context: ../rootly-analytics-backend
      dockerfile: Dockerfile
    restart: unless-stopped
    expose:
      - "8000"
    depends_on:
      db-data-processing:
        condition: service_healthy
      stg-data-processing:
        condition: service_healthy
      cache-analytics:
        condition: service_healthy
    networks:
      - rootly-private-network
    deploy:
      replicas: ${ANALYTICS_REPLICAS:-1}
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # API Gateway (Go) - GraphQL + REST Proxy
  api-gateway:
    build:
      context: ../rootly-apigateway
      dockerfile: Dockerfile
    container_name: api-gateway
    restart: unless-stopped
    ports:
      - "${API_GATEWAY_EXTERNAL_PORT:-8080}:8080"
    depends_on:
      be-authentication-and-roles:
        condition: service_started
      be-user-plant-management:
        condition: service_started
      be-data-processing:
        condition: service_started
      load-balancer-analytics:
        condition: service_started
    networks:
      - rootly-private-network
      - rootly-public-network
    env_file:
      - .env
    environment:
      - PORT=8080
      - CORS_ALLOW_ALL_ORIGINS=${CORS_ALLOW_ALL_ORIGINS:-true}
      - GRAPHQL_PLAYGROUND_ENABLED=${GRAPHQL_PLAYGROUND_ENABLED:-true}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - AUTH_SERVICE_URL=http://be-authentication-and-roles:8000
      - PLANT_MANAGEMENT_SERVICE_URL=http://be-user-plant-management:8000
      - DATA_MANAGEMENT_SERVICE_URL=http://be-data-management:8000
      - ANALYTICS_SERVICE_URL=http://load-balancer-analytics:80

  # Authentication Backend (Python) - Handles user authentication and management
  be-authentication-and-roles:
    build:
      context: ../rootly-authentication-and-roles-backend
      dockerfile: Dockerfile
    container_name: be-authentication-and-roles
    restart: unless-stopped
    depends_on:
      db-authentication-and-roles:
        condition: service_healthy
      stg-authentication-and-roles:
        condition: service_healthy
    networks:
      - rootly-private-network
    env_file:
      - .env
    environment:
      - MINIO_ENDPOINT=stg-authentication-and-roles:9000
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-admin123}@db-authentication-and-roles:5432/${POSTGRES_DB:-authentication_and_roles_db}
      - DB_HOST=db-authentication-and-roles
      - DB_PORT=5432
      - DB_USER=${POSTGRES_USER:-admin}
      - DB_PASSWORD=${POSTGRES_PASSWORD:-admin123}
      - DB_NAME=${POSTGRES_DB:-authentication_and_roles_db}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${SERVERS_INTERNAL_PORT:-8000}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # User Plant Management Backend (Python) - Handles user plant management
  be-user-plant-management:
    build:
      context: ../rootly-user-plant-management-backend
      dockerfile: Dockerfile
    container_name: be-user-plant-management
    restart: unless-stopped
    depends_on:
      db-user-plant-management:
        condition: service_healthy
      stg-user-plant-management:
        condition: service_healthy
    networks:
      - rootly-private-network
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER_PLANT_USER:-admin}:${POSTGRES_USER_PLANT_PASSWORD:-admin123}@db-user-plant-management:5432/${POSTGRES_USER_PLANT_DB:-user_plant_management_db}
      - MINIO_ENDPOINT=stg-user-plant-management:9000
      - MINIO_ACCESS_KEY=${MINIO_USER_PLANT_ROOT_USER:-admin}
      - MINIO_SECRET_KEY=${MINIO_USER_PLANT_ROOT_PASSWORD:-admin123}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Frontend SSR (Next.js) - User interface for the agricultural monitoring platform
  frontend-ssr:
    build:
      context: ../rootly-ssr-frontend
      dockerfile: Dockerfile
    container_name: frontend-ssr
    restart: unless-stopped
    depends_on:
      api-gateway:
        condition: service_started
    networks:
      - rootly-private-network
    expose:
      - "3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - BASE_URL=https://rootly-waf
      - API_GATEWAY_URL=http://api-gateway:8080
      - NEXT_PUBLIC_API_GATEWAY_URL=/api
      - AUTH_SERVICE_URL=http://api-gateway:8080
      - PLANT_SERVICE_URL=http://api-gateway:8080
    healthcheck:
      test: ["CMD-SHELL", "wget --no-check-certificate --spider -q https://127.0.0.1:3001 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  rootly-waf:
    build:
      context: ../rootly-waf
      dockerfile: Dockerfile
    container_name: rootly-waf
    depends_on:
      frontend-ssr:
        condition: service_healthy
      api-gateway:
        condition: service_started
    ports:
      - "${ROOTLY_WAF_HTTP_PORT:-80}:80"
      - "${ROOTLY_WAF_HTTPS_PORT:-443}:443"
    networks:
      - rootly-public-network
      - rootly-private-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-kf", "https://127.0.0.1:443/"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s

# ============================================================================
# VOLUMES
# ============================================================================

volumes:
  influxdb_data:
    driver: local
  minio_data:
    driver: local
  postgres_data:
    driver: local
  minio_auth_data:
    driver: local
  postgres_user_plant_data:
    driver: local
  minio_user_plant_data:
    driver: local
  redis_analytics_data:
    driver: local

# ============================================================================
# NETWORKS
# ============================================================================

networks:
  rootly-public-network:
    driver: bridge
    name: rootly-public-network
  rootly-private-network:
    driver: bridge
    name: rootly-private-network
    internal: true
